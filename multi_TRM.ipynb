{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:13:48.870947Z",
     "start_time": "2023-03-16T06:13:48.850991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:13:49.527838Z",
     "start_time": "2023-03-16T06:13:49.516377Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参数\n",
    "input_window = 100\n",
    "output_window = 5\n",
    "batch_size = 32 # batch size\n",
    "\n",
    "# This concept is also called teacher forceing. \n",
    "# The flag decides if the loss will be calculted over all \n",
    "# or just the predicted values.\n",
    "# calculate_loss_over_all_values = False\n",
    "calculate_loss_over_all_values = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:13:50.603940Z",
     "start_time": "2023-03-16T06:13:50.589948Z"
    }
   },
   "outputs": [],
   "source": [
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=20000):\n",
    "        super(PositionalEncoding, self).__init__()  \n",
    "        # max_len参数指定模型将能够处理的最大序列长度，而d_model参数指定输入嵌入的维数\n",
    "        # pe将为输入序列中的每个位置（最多max_len）提供一行，并为每个嵌入维度提供d_model列。\n",
    "        # 计算位置编码的值\n",
    "        pos = torch.arange(max_len).unsqueeze(1)\n",
    "        i = torch.arange(d_model).unsqueeze(0)\n",
    "        angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / torch.tensor(d_model).float())\n",
    "        angle_rads = pos * angle_rates\n",
    "        # 使用正弦和余弦函数来产生位置编码\n",
    "        pe = torch.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = torch.sin(angle_rads[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle_rads[:, 1::2])\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "#         pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x + self.pe[:x.size(0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:13:51.196407Z",
     "start_time": "2023-03-16T06:13:51.169479Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型架构\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=7,num_layers=3,dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=7, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(feature_size,feature_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self,src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            # print('a',src.size())\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        src.size()\n",
    "        # print('j',src.size(),self.src_mask.size())\n",
    "        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:13:51.948020Z",
     "start_time": "2023-03-16T06:13:51.927076Z"
    }
   },
   "outputs": [],
   "source": [
    "# 划分数据窗口\n",
    "# if window is 100 and prediction step is 1\n",
    "# in -> [0..99]\n",
    "# target -> [1..100]\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        # 数据和标签\n",
    "        # 对数据进行最后output_window窗口的预测，因此用0代替\n",
    "        train_seq = np.append(input_data[i:i+tw,:][:-output_window,:] , np.zeros((output_window,7)),axis=0)\n",
    "        train_label = input_data[i:i+tw,:]\n",
    "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    # 转化成张量\n",
    "    return torch.FloatTensor(inout_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:13:52.730947Z",
     "start_time": "2023-03-16T06:13:52.711677Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据并处理\n",
    "def get_data():\n",
    "    \n",
    "    # 导入原数据\n",
    "    data = pd.read_csv('./ETTDataset/ETTh1.csv')\n",
    "    c_all=pd.Series(data.columns.drop('date'))\n",
    "    # 归一化\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
    "    data_c_all = data.loc[:, c_all]\n",
    "    series = data_c_all.to_numpy()\n",
    "    amplitude = scaler.fit_transform(series)\n",
    "    # amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    # 切分训练集和测试集\n",
    "    split_train = int(amplitude.shape[0] * 0.7)\n",
    "    train = amplitude[:split_train]\n",
    "    test_data = amplitude[split_train:]\n",
    "    split_test = int(test_data.shape[0] * 0.5)\n",
    "    valid = test_data[:split_test]\n",
    "    test = test_data[split_test:]\n",
    "    \n",
    "    # 窗口为input_window，将数据划分成(带标签的)训练和测试数据，并转化为张量\n",
    "    # 转化训练数据\n",
    "    train_sequence = create_inout_sequences(train,input_window)\n",
    "    # 最后 output_window 为预测窗口的大小\n",
    "    train_sequence = train_sequence[:-output_window]\n",
    "    \n",
    "    # 转化测试数据\n",
    "    valid_sequence = create_inout_sequences(valid,input_window)\n",
    "    valid_sequence = valid_sequence[:-output_window]\n",
    "    \n",
    "    # 转化测试数据\n",
    "    test_sequence = create_inout_sequences(test,input_window)\n",
    "    test_sequence = test_sequence[:-output_window]\n",
    "\n",
    "    return train_sequence.to(device), valid_sequence.to(device), test_sequence.to(device),scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:13:53.791247Z",
     "start_time": "2023-03-16T06:13:53.776409Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据转化：输入标签\n",
    "def get_batch(source, i,batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]   \n",
    "    # 数据切分成 输入和标签\n",
    "    # 数据维度转化为[input_window,batch_size,1]\n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)).squeeze() # 1 is feature size\n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1)).squeeze()\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:14:03.227234Z",
     "start_time": "2023-03-16T06:13:54.638963Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12089, 2, 100, 7]) torch.Size([2508, 2, 100, 7]) torch.Size([2508, 2, 100, 7])\n",
      "torch.Size([100, 32, 7]) torch.Size([100, 32, 7])\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data, scaler = get_data()\n",
    "print(train_data.size(), valid_data.size(), test_data.size())\n",
    "# print(train_data.size(), val_data.size())\n",
    "tr,te = get_batch(train_data, 0,batch_size)\n",
    "print(tr.shape,te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T04:45:14.754615Z",
     "start_time": "2023-03-16T04:45:14.732676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 7])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T04:45:15.949108Z",
     "start_time": "2023-03-16T04:45:15.935145Z"
    }
   },
   "outputs": [],
   "source": [
    "tr1,te1 = get_batch(train_data, 10,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T04:45:18.327402Z",
     "start_time": "2023-03-16T04:45:18.286956Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9366e-01, -1.8023e-02,  2.7639e-01,  ..., -1.4454e-01,\n",
       "           2.9635e-01, -3.9312e-02],\n",
       "         [ 2.2831e-01, -1.8023e-02,  2.8643e-01,  ..., -4.3981e-02,\n",
       "           2.9635e-01, -3.3721e-02],\n",
       "         [ 1.8209e-01, -1.8023e-02,  2.6800e-01,  ..., -1.6973e-01,\n",
       "           3.1039e-01, -7.0218e-02],\n",
       "         ...,\n",
       "         [ 4.3064e-01,  3.3329e-01,  5.1090e-01,  ..., -1.8233e-01,\n",
       "           4.0684e-01,  4.2147e-02],\n",
       "         [ 4.0462e-01,  2.8837e-01,  5.1425e-01,  ..., -1.5713e-01,\n",
       "           4.2087e-01, -1.1240e-02],\n",
       "         [ 4.0751e-01,  2.8837e-01,  5.0755e-01,  ..., -8.7962e-02,\n",
       "           4.0684e-01,  1.7979e-01]],\n",
       "\n",
       "        [[ 2.2831e-01, -1.8023e-02,  2.8643e-01,  ..., -4.3981e-02,\n",
       "           2.9635e-01, -3.3721e-02],\n",
       "         [ 1.8209e-01, -1.8023e-02,  2.6800e-01,  ..., -1.6973e-01,\n",
       "           3.1039e-01, -7.0218e-02],\n",
       "         [ 1.8209e-01, -3.2067e-08,  2.6635e-01,  ..., -1.1315e-01,\n",
       "           3.5160e-01, -9.5494e-02],\n",
       "         ...,\n",
       "         [ 4.0462e-01,  2.8837e-01,  5.1425e-01,  ..., -1.5713e-01,\n",
       "           4.2087e-01, -1.1240e-02],\n",
       "         [ 4.0751e-01,  2.8837e-01,  5.0755e-01,  ..., -8.7962e-02,\n",
       "           4.0684e-01,  1.7979e-01],\n",
       "         [ 4.3931e-01,  2.7034e-01,  5.0920e-01,  ..., -5.6577e-02,\n",
       "           4.3446e-01,  1.9664e-01]],\n",
       "\n",
       "        [[ 1.8209e-01, -1.8023e-02,  2.6800e-01,  ..., -1.6973e-01,\n",
       "           3.1039e-01, -7.0218e-02],\n",
       "         [ 1.8209e-01, -3.2067e-08,  2.6635e-01,  ..., -1.1315e-01,\n",
       "           3.5160e-01, -9.5494e-02],\n",
       "         [ 1.9940e-01,  3.6046e-02,  2.9817e-01,  ..., -2.2631e-01,\n",
       "           2.6919e-01, -5.6202e-02],\n",
       "         ...,\n",
       "         [ 4.0751e-01,  2.8837e-01,  5.0755e-01,  ..., -8.7962e-02,\n",
       "           4.0684e-01,  1.7979e-01],\n",
       "         [ 4.3931e-01,  2.7034e-01,  5.0920e-01,  ..., -5.6577e-02,\n",
       "           4.3446e-01,  1.9664e-01],\n",
       "         [ 4.1618e-01,  2.2529e-01,  4.9582e-01,  ..., -1.1315e-01,\n",
       "           4.0684e-01,  2.7526e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:42:40.388831Z",
     "start_time": "2023-03-16T06:42:40.352959Z"
    }
   },
   "outputs": [],
   "source": [
    "tr2,te2 = get_batch(train_data, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:43:17.853567Z",
     "start_time": "2023-03-16T06:43:17.834588Z"
    }
   },
   "outputs": [],
   "source": [
    "tr2.shape\n",
    "tr2 = tr2.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:43:25.367629Z",
     "start_time": "2023-03-16T06:43:25.357954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 7])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:14:30.092523Z",
     "start_time": "2023-03-16T06:14:30.078558Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train(model, optimizer, criterion, scheduler, epoch, train_data):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
    "        # 数据切分成 输入数据和标签\n",
    "        data, targets = get_batch(train_data, i,batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        # calculate_loss_over_all_values 为True时，损失将在所有输出值和目标值上计算\n",
    "        # 为False时，损失仅计算 output 和 targets 的最后 output_window 个值\n",
    "        if calculate_loss_over_all_values:\n",
    "            loss = criterion(output, targets)\n",
    "        else:\n",
    "            loss = criterion(output[-output_window:], targets[-output_window:])\n",
    "    \n",
    "        loss.backward()\n",
    "        # 执行梯度裁剪的函数,parameters参数是表示神经网络参数梯度的张量列表\n",
    "        # max_norm参数是梯度的最大范数，即当参数的范数大于max_norm时，就会对梯度进行削减\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 计算累积的损失值\n",
    "        total_loss += loss.item()\n",
    "        # 计算打印日志的间隔，设置为训练集大小的5分之一\n",
    "        log_interval = int(len(train_data) / batch_size / 5)\n",
    "        # batch 是 log_interval 的倍数且不是第 0 个 batch时，开始打印日志\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            # 计算当前平均损失\n",
    "            cur_loss = total_loss / log_interval\n",
    "            # 计算从训练开始到现在的时间\n",
    "            elapsed = time.time() - start_time\n",
    "            # 打印日志，其中包括当前 epoch，batch，学习率，时间，损失值和困惑度\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            # 重置 total_loss，以便下一个 log_interval 计算新的平均损失值\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:14:31.773710Z",
     "start_time": "2023-03-16T06:14:31.726838Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_and_loss(eval_model, data_source,epoch,scaler):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i,1)\n",
    "            data = data.unsqueeze(1)\n",
    "            target = target.unsqueeze(1)\n",
    "\n",
    "            # look like the model returns static values for the output window\n",
    "            output = eval_model(data)   \n",
    "\n",
    "            if calculate_loss_over_all_values:                                \n",
    "                total_loss += criterion(output, target).item()\n",
    "            else:\n",
    "                total_loss += criterion(output[-output_window:], target[-output_window:]).item()\n",
    "            \n",
    "            \n",
    "            test_result = torch.cat((test_result, output[-1,:].squeeze(1).cpu()), 0) #todo: check this. -> looks good to me\n",
    "            truth = torch.cat((truth, target[-1,:].squeeze(1).cpu()), 0)\n",
    "            \n",
    "    #test_result = test_result.cpu().numpy()\n",
    "    len(test_result)\n",
    "    \n",
    "    print(test_result.size(),truth.size())\n",
    "    test_result=scaler.inverse_transform(test_result.reshape(-1, 1)).reshape(-1)\n",
    "    truth=scaler.inverse_transform(truth.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    pyplot.plot(test_result,color=\"red\")\n",
    "    pyplot.plot(truth[:500],color=\"blue\")\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.xlabel(\"Periods\")\n",
    "    pyplot.ylabel(\"Y\")\n",
    "    pyplot.savefig('graph/transformer-epoch%d.png'%epoch)\n",
    "    pyplot.close()\n",
    "    return total_loss / i\n",
    "\n",
    "\n",
    "# 预测将来的时间步，steps 表示预测的步长\n",
    "def predict_future(eval_model, data_source,steps,epoch,scaler):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    # 这里的 data 为真值\n",
    "    _ , data = get_batch(data_source, 0,1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps,1):\n",
    "            input = torch.clone(data[-input_window:])\n",
    "            input[-output_window:] = 0     \n",
    "            output = eval_model(data[-input_window:])                        \n",
    "            data = torch.cat((data, output[-1:]))\n",
    "            \n",
    "    data = data.cpu().view(-1)\n",
    "    \n",
    "    data=scaler.inverse_transform(data.reshape(-1, 1)).reshape(-1)\n",
    "    pyplot.plot(data,color=\"red\")       \n",
    "    pyplot.plot(data[:input_window],color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-future%d.png'%epoch)\n",
    "    pyplot.close()\n",
    "        \n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    # 设置评估输入的batch大小 eval_batch_size\n",
    "    eval_batch_size = 1000\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
    "            data, targets = get_batch(data_source, i,eval_batch_size)\n",
    "            output = eval_model(data) \n",
    "\n",
    "            if calculate_loss_over_all_values:\n",
    "                # len(data[0]) eval_batch_size的大小乘以损失\n",
    "                total_loss += len(data[0])* criterion(output, targets).item()\n",
    "            else:                                \n",
    "                total_loss += len(data[0])* criterion(output[-output_window:], targets[-output_window:]).item()   \n",
    "\n",
    "    # 对所有验证数据输出 损失\n",
    "    return total_loss / len(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测将来的时间步，steps 表示预测的步长\n",
    "def predict_future(eval_model, data_source, steps, scaler):\n",
    "    eval_model.eval() \n",
    "\n",
    "    # 这里的 targets 为真值, 取第一个数据[1, 2, 100, 7]进行预测将来。\n",
    "    datas, targets = get_batch(data_source, 0, 1)\n",
    "    data = datas.unsqueeze(1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps, 1):\n",
    "            input = torch.clone(data[-input_window:]) \n",
    "            output = eval_model(input)\n",
    "            # 只将最后一行预测 进行加入\n",
    "            data = torch.cat((datas, output[-1,:]))\n",
    "            \n",
    "    data=scaler.inverse_transform(data.reshape(-1, 1)).reshape(-1)\n",
    "    pyplot.plot(data,color=\"red\")       \n",
    "    pyplot.plot(data[:input_window],color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-future%d.png'%steps)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:14:32.728358Z",
     "start_time": "2023-03-16T06:14:32.704372Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(eval_model, data_source,epoch,scaler):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i,1)\n",
    "            data = data.unsqueeze(1)\n",
    "            target = target.unsqueeze(1)            \n",
    "            # look like the model returns static values for the output window\n",
    "            output = eval_model(data)\n",
    "            if calculate_loss_over_all_values:                                \n",
    "                total_loss += criterion(output, target).item()\n",
    "            else:\n",
    "                total_loss += criterion(output[-output_window:], target[-output_window:]).item()\n",
    "            \n",
    "            test_result = torch.cat((test_result, output[-1,:].squeeze(1).cpu()), 0) #todo: check this. -> looks good to me\n",
    "            truth = torch.cat((truth, target[-1,:].squeeze(1).cpu()), 0)\n",
    "#             test_result = torch.cat((test_result, output[-1,:].cpu()), 0) #todo: check this. -> looks good to me\n",
    "#             truth = torch.cat((truth, target[-1,:].cpu()), 0)\n",
    "            \n",
    "    #test_result = test_result.cpu().numpy()\n",
    "    len(test_result)\n",
    "    \n",
    "    # 取[:700]的数据进行 时序预测效果的展示\n",
    "    test_result_=scaler.inverse_transform(test_result[:700])\n",
    "    truth_=scaler.inverse_transform(truth)\n",
    "#     print(test_result.shape,truth.shape)\n",
    "    for m in range(data_source.shape[-1]):\n",
    "        test_result = test_result_[:,m]\n",
    "        truth = truth_[:,m]\n",
    "        fig = pyplot.figure(1, figsize=(20, 5))\n",
    "        fig.patch.set_facecolor('xkcd:white')\n",
    "        # 对测试结果 test_result [510:] 之后的数据进行预测展示\n",
    "        pyplot.plot([k + 510                 for k in range(190)],test_result[510:],color=\"red\")\n",
    "        pyplot.title('Prediction uncertainty')\n",
    "        pyplot.plot(truth[:700],color=\"black\")\n",
    "        pyplot.legend([\"prediction\", \"true\"], loc=\"upper left\")\n",
    "        ymin, ymax = pyplot.ylim()\n",
    "        # 画出分界限\n",
    "        pyplot.vlines(510, ymin, ymax, color=\"blue\", linestyles=\"dashed\", linewidth=2)\n",
    "        pyplot.ylim(ymin, ymax)\n",
    "        pyplot.xlabel(\"Periods\")\n",
    "        pyplot.ylabel(\"Y\")\n",
    "        pyplot.show()\n",
    "        pyplot.close()\n",
    "    return total_loss / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:14:42.271498Z",
     "start_time": "2023-03-16T06:14:33.284465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_23556\\1687738998.py:11: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / torch.tensor(d_model).float())\n"
     ]
    }
   ],
   "source": [
    "# 获取数据和模型\n",
    "# train_data, val_data,scaler = get_data()\n",
    "train_data, valid_data, test_data, scaler = get_data()\n",
    "model = TransAm().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:14:50.173541Z",
     "start_time": "2023-03-16T06:14:50.153793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransAm(\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=7, out_features=7, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=7, bias=True)\n",
       "    (norm1): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=7, out_features=7, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=7, bias=True)\n",
       "        (norm1): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=7, out_features=7, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=7, bias=True)\n",
       "        (norm1): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=7, out_features=7, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=7, bias=True)\n",
       "        (norm1): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=7, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T06:15:07.331603Z",
     "start_time": "2023-03-16T06:14:53.790239Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    75/  377 batches | lr 0.010000 | 34.13 ms | loss 0.09880 | ppl     1.10\n",
      "| epoch   1 |   150/  377 batches | lr 0.010000 | 31.08 ms | loss 0.06616 | ppl     1.07\n",
      "| epoch   1 |   225/  377 batches | lr 0.010000 | 31.24 ms | loss 0.05191 | ppl     1.05\n",
      "| epoch   1 |   300/  377 batches | lr 0.010000 | 31.18 ms | loss 0.08892 | ppl     1.09\n",
      "| epoch   1 |   375/  377 batches | lr 0.010000 | 30.77 ms | loss 0.07875 | ppl     1.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 12.67s | valid loss 0.07283 | valid ppl     1.08\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [89], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 训练模型 损失\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 验证损失\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "Cell \u001b[1;32mIn [84], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, scheduler, epoch, train_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m data, targets \u001b[38;5;241m=\u001b[39m get_batch(train_data, i,batch_size)\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# calculate_loss_over_all_values 为True时，损失将在所有输出值和目标值上计算\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 为False时，损失仅计算 output 和 targets 的最后 output_window 个值\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calculate_loss_over_all_values:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [79], line 29\u001b[0m, in \u001b[0;36mTransAm.forward\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m     27\u001b[0m src\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# print('j',src.size(),self.src_mask.size())\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, self.src_mask)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:202\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    199\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 202\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:345\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m--> 345\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:360\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 360\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\xai3\\lib\\site-packages\\torch\\nn\\functional.py:1279\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[1;32m-> 1279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_data, val_data,scaler = get_data()\n",
    "# train_data, valid_data, test_data, scaler = get_data()\n",
    "# model = TransAm().to(device)\n",
    "\n",
    "# 一些超参数\n",
    "\n",
    "epochs = 100 # The number of epochs\n",
    "lr = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "\n",
    "# 初始化为正无穷大，确保第一次比较时，任何值都比 best_val_loss 更小\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    # 训练模型 损失\n",
    "    train(model, optimizer, criterion, scheduler, epoch, train_data)\n",
    "    \n",
    "    # 验证损失\n",
    "    if(epoch % 10 == 0):\n",
    "        val_loss = plot(model, valid_data, epoch, scaler)\n",
    "        # predict_future(model, val_data,200,epoch,scaler)\n",
    "    else:\n",
    "        val_loss = evaluate(model, valid_data)\n",
    "        \n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        # 将 best_val_loss 更新为当前的验证损失值\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai3",
   "language": "python",
   "name": "xai3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
